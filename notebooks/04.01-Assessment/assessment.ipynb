{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/nvidia_header.png\" style=\"margin-left: -30px; width: 300px; float: left;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessment: Accelerate and Optimize Maxwell's Equations Simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Maxwell's Equations](https://en.wikipedia.org/wiki/Maxwell%27s_equations) simulator predicts how electromagnetic waves propagate. \n",
    "For this assessment, you'll begin with a simple, though working, 2D Maxwell's Equations simulator. In its current CPU-only form, this application takes about 15 seconds to run on 4096^2 cells, and 4 minutes to run on 65536^2 cells. \n",
    "Your task is to GPU-accelerate the program, retaining the correctness of the simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "[The Problem](#The-Problem)<br>\n",
    "[Scoring](#Scoring)<br>\n",
    "[Step 1: Port CPU Simulator to GPU](#Step-1:-Port-CPU-Simulator-to-GPU)<br>\n",
    "[Step 2: Accelerate the Simulator with Fancy Iterators](#Step-2:-Accelerate-the-Simulator-with-Fancy-Iterators)<br>\n",
    "[Step 3: Coarse Grid with CUDA Kernel](#Step-3:-Coarse-Grid-with-CUDA-Kernel)<br>\n",
    "[Step 4: Submit Your Assessment](#Step-4:-Submit-Your-Assessment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# The Problem\n",
    "\n",
    "The provided code simulates the propagation of electromagnetic waves in a 2D grid using Maxwell's equations. It performs iterative updates of the electric and magnetic fields, accounting for spatial and temporal changes.  The use of CPU-based computation limits the performance as it is scaled up.  Your job is to accelerate the computation using techniques learned in this class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Scoring\n",
    "You will be assessed on your ability to accelerate the simulator in three steps, from basic parallelization to employing fancy iterators, and finally using a course grid kernel.   This coding assessment is worth 100 points, divided as follows:\n",
    "\n",
    "### Rubric\n",
    "\n",
    "| Step                                              | FIXMEs?  | Points |\n",
    "|---------------------------------------------------|----------|--------|\n",
    "| 1. Port CPU Simulator to GPU                      |  2       | 50     |\n",
    "| 2. Accelerate the Simulator with Fancy Iterators |  3       | 25     |\n",
    "| 3. Use Cooperative Algorithms to Coarse the Grid  |  3       | 25     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although you are very capable at this point of building the project without any help at all, some scaffolding is provided.\n",
    "Sources for each of the steps have a few FIXMEs to help you focus on the most important changes.\n",
    "\n",
    "Once you are confident that you've built a correct and optimized application, follow the instructions for submission (Step 4) at the end of the notebook.\n",
    "\n",
    "### Resources and Hints\n",
    "\n",
    "**Step 1**\n",
    "  * Refer to [1.2 Execution Spaces](../01.02-Execution-Spaces/01.02.01-Execution-Spaces.ipynb) for guidance on how to port CPU algorithms to GPU.\n",
    "  * Refer to [1.6 Memory Spaces](../01.06-Memory-Spaces/01.06.01-Memory-Spaces.ipynb) for guidance on how to leverage explicit memory spaces.\n",
    "  * For your initial refactors, aim to keep the application's logic, especially the lambda functions, mostly unchanged. Focus on accelerating it in the simplest way possible.\n",
    "  * After your changes, all `FIXME(Step 1)` comments should be addressed.\n",
    "\n",
    "**Step 2**\n",
    "  * Refer to [1.3 Extending Algorithms](../01.03-Extending-Algorithms/01.03.01-Extending-Algorithms.ipynb) for guidance on how to avoid materialization of temporary values in memory.\n",
    "  * After your changes, all `FIXME(Step 2)` comments should be addressed.\n",
    "\n",
    "**Step 3**\n",
    "  * Refer to [3.6 Cooperative Algorithms](../03.06-Cooperative-Algorithms/03.06.01-Cooperative.ipynb) for guidance on how to avoid materialization of temporary values in memory.\n",
    "\n",
    "**Have Fun!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# Step 1: Port CPU Simulator to GPU\n",
    "\n",
    "Begin by importing the assessment evaluator code and a fresh copy of the the simple, CPU-only version of the simulator into your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the evaluator Python code\n",
    "import Sources.dli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by checking the throughput and visualizing the results of the Maxwell's Equations simulator. \n",
    "Run the cell below to check CPU performance and visualize the results. \n",
    "The entire simulator has already been ported to GPU, so the initial state for the simulation is provided as device containers. \n",
    "\n",
    "However, `simulate()` is still lacking GPU acceleration. \n",
    "It copies data to *host*, performs the simulation, and copies data back to *device*.\n",
    "Your task is to get rid of all copies to *host* and run the simulation in the provided *device* containers instead.\n",
    "\n",
    "```c++\n",
    "// Do not change the signature of this function\n",
    "void simulate(int cells_along_dimension, float dx, float dy, float dt,\n",
    "              thrust::device_vector<float> &d_hx,\n",
    "              thrust::device_vector<float> &d_hy,\n",
    "              thrust::device_vector<float> &d_dz,\n",
    "              thrust::device_vector<float> &d_ez) \n",
    "{\n",
    "  // Remove host containers and compute in the incoming device containers\n",
    "  std::vector<float> hx = copy_to_host(d_hx);\n",
    "  std::vector<float> hy = copy_to_host(d_hy);\n",
    "  std::vector<float> dz = copy_to_host(d_dz);\n",
    "  std::vector<float> ez = copy_to_host(d_ez);\n",
    "\n",
    "  int cells = cells_along_dimension * cells_along_dimension;\n",
    "  std::vector<float> buffer(cells);\n",
    "\n",
    "  // Materialize cell indices (`i`) in memory\n",
    "  std::vector<int> cell_ids(cells);\n",
    "  for (int i = 0; i < cells; i++) {\n",
    "    cell_ids[i] = i;\n",
    "  }\n",
    "\n",
    "  for (int step = 0; step < dli::steps; step++) {\n",
    "    update_hx(cells_along_dimension, dx, dy, dt, hx, ez, buffer);\n",
    "    update_hy(cells_along_dimension, dx, dy, dt, hy, ez, buffer);\n",
    "    update_dz(cells_along_dimension, dx, dy, dt, hx, hy, dz, cell_ids);\n",
    "    update_ez(ez, dz);\n",
    "  }\n",
    "\n",
    "  // Copy back to device\n",
    "  d_hx = hx;\n",
    "  d_hy = hy;\n",
    "  d_dz = dz;\n",
    "  d_ez = ez;\n",
    "}\n",
    "```\n",
    "\n",
    "Nevertheless, as written, the simulator works correctly.\n",
    "Below you can see how electromagnetic waves propagate in a 2D grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sources.dli.run_step_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To GPU-accelerate `simulate()`, please edit the code below to port all algorithms to GPU using Thrust.\n",
    "Your changes shouldn't affect visualization, but you are expected to improve the throughput that the simulator reports. \n",
    "\n",
    "If you want to start again, just copy the backup source [Backup/maxwell.cu](Backup/maxwell.cu).\n",
    "\n",
    "<details>\n",
    "<summary>Original code in case you need it</summary>\n",
    "\n",
    "```c++\n",
    "%%writefile Sources/maxwell.cu\n",
    "#include \"dli.h\"\n",
    "\n",
    "// FIXME(Step 1):\n",
    "// accept device containers instead of `std::vector<float>`\n",
    "void update_hx(int n, float dx, float dy, float dt, std::vector<float> &hx,\n",
    "               std::vector<float> &ez, std::vector<float> &buffer) {\n",
    "  // FIXME(Step 2):\n",
    "  // Use zip and transform iterators to avoid materializing `ez[i + n] - ez[i]`\n",
    "  // FIXME(Step 1):\n",
    "  // compute transformation on GPU\n",
    "  std::transform(ez.begin() + n, ez.end(), ez.begin(), buffer.begin(),\n",
    "                 [](float x, float y) { return x - y; });\n",
    "\n",
    "  // FIXME(Step 1):\n",
    "  // compute transformation on GPU\n",
    "  std::transform(hx.begin(), hx.end() - n, buffer.begin(), hx.begin(),\n",
    "                 [dt, dx, dy](float h, float cex) {\n",
    "                   return h - dli::C0 * dt / 1.3f * cex / dy;\n",
    "                 });\n",
    "}\n",
    "\n",
    "// FIXME(Step 1):\n",
    "// accept device containers instead of `std::vector<float>`\n",
    "void update_hy(int n, float dx, float dy, float dt, std::vector<float> &hy,\n",
    "               std::vector<float> &ez, std::vector<float> &buffer) {\n",
    "  // FIXME(Step 2):\n",
    "  // Use zip and transform iterators to avoid materializing `ez[i] - ez[i + 1]`\n",
    "  // FIXME(Step 1):\n",
    "  // compute transformation on GPU\n",
    "  std::transform(ez.begin(), ez.end() - 1, ez.begin() + 1, buffer.begin(),\n",
    "                 [](float x, float y) { return x - y; });\n",
    "\n",
    "  // FIXME(Step 1):\n",
    "  // compute transformation on GPU\n",
    "  std::transform(hy.begin(), hy.end() - 1, buffer.begin(), hy.begin(),\n",
    "                 [dt, dx, dy](float h, float cey) {\n",
    "                   return h - dli::C0 * dt / 1.3f * cey / dx;\n",
    "                 });\n",
    "}\n",
    "\n",
    "// FIXME(Step 1):\n",
    "// accept device containers instead of `std::vector<float>`\n",
    "void update_dz(int n, float dx, float dy, float dt, std::vector<float> &hx_vec,\n",
    "               std::vector<float> &hy_vec, std::vector<float> &dz_vec,\n",
    "               std::vector<int> &cell_ids) {\n",
    "  auto hx = hx_vec.begin();\n",
    "  auto hy = hy_vec.begin();\n",
    "  auto dz = dz_vec.begin();\n",
    "\n",
    "  // FIXME(Step 1):\n",
    "  // compute for each on GPU\n",
    "  std::for_each(cell_ids.begin(), cell_ids.end(),\n",
    "                [n, dx, dy, dt, hx, hy, dz](int cell_id) {\n",
    "                  if (cell_id > n) {\n",
    "                    float hx_diff = hx[cell_id - n] - hx[cell_id];\n",
    "                    float hy_diff = hy[cell_id] - hy[cell_id - 1];\n",
    "                    dz[cell_id] += dli::C0 * dt * (hx_diff / dx + hy_diff / dy);\n",
    "                  }\n",
    "                });\n",
    "}\n",
    "\n",
    "// FIXME(Step 1):\n",
    "// accept device containers instead of `std::vector<float>`\n",
    "void update_ez(std::vector<float> &ez, std::vector<float> &dz) {\n",
    "  // FIXME(Step 1):\n",
    "  // compute transformation on GPU\n",
    "  std::transform(dz.begin(), dz.end(), ez.begin(),\n",
    "                 [](float d) { return d / 1.3f; });\n",
    "}\n",
    "\n",
    "// FIXME(Step 1):\n",
    "// remove this function\n",
    "std::vector<float> copy_to_host(const thrust::device_vector<float> &d_vec) {\n",
    "  std::vector<float> vec(d_vec.size());\n",
    "  thrust::copy(d_vec.begin(), d_vec.end(), vec.begin());\n",
    "  return vec;\n",
    "}\n",
    "\n",
    "// Do not change the signature of this function\n",
    "void simulate(int cells_along_dimension, float dx, float dy, float dt,\n",
    "              thrust::device_vector<float> &d_hx,\n",
    "              thrust::device_vector<float> &d_hy,\n",
    "              thrust::device_vector<float> &d_dz,\n",
    "              thrust::device_vector<float> &d_ez) {\n",
    "  // FIXME(Step 1):\n",
    "  // remove host containers and compute in the incoming device containers\n",
    "  std::vector<float> hx = copy_to_host(d_hx);\n",
    "  std::vector<float> hy = copy_to_host(d_hy);\n",
    "  std::vector<float> dz = copy_to_host(d_dz);\n",
    "  std::vector<float> ez = copy_to_host(d_ez);\n",
    "\n",
    "  // FIXME(Step 2):\n",
    "  // Remove `cell_ids` vector and use counting iterator instead\n",
    "  int cells = cells_along_dimension * cells_along_dimension;\n",
    "  std::vector<int> cell_ids(cells);\n",
    "  for (int i = 0; i < cells; i++) {\n",
    "    cell_ids[i] = i;\n",
    "  }\n",
    "\n",
    "  // FIXME(Step 2):\n",
    "  // Remove `buffer` vector and use fancy iterators instead\n",
    "  std::vector<float> buffer(cells);\n",
    "\n",
    "  for (int step = 0; step < dli::steps; step++) {\n",
    "    update_hx(cells_along_dimension, dx, dy, dt, hx, ez, buffer);\n",
    "    update_hy(cells_along_dimension, dx, dy, dt, hy, ez, buffer);\n",
    "    update_dz(cells_along_dimension, dx, dy, dt, hx, hy, dz, cell_ids);\n",
    "    update_ez(ez, dz);\n",
    "  }\n",
    "\n",
    "  // FIXME(Step 1):\n",
    "  // remove copy to host containers, compute in the incoming device containers\n",
    "  d_hx = hx;\n",
    "  d_hy = hy;\n",
    "  d_dz = dz;\n",
    "  d_ez = ez;\n",
    "}\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Sources/maxwell.cu\n",
    "#include \"dli.h\"\n",
    "\n",
    "// FIXME(Step 1):\n",
    "// accept device containers instead of `std::vector<float>`\n",
    "void update_hx(int n, float dx, float dy, float dt, std::vector<float> &hx,\n",
    "               std::vector<float> &ez, std::vector<float> &buffer) {\n",
    "  // FIXME(Step 2):\n",
    "  // Use zip and transform iterators to avoid materializing `ez[i + n] - ez[i]`\n",
    "  // FIXME(Step 1):\n",
    "  // compute transformation on GPU\n",
    "  std::transform(ez.begin() + n, ez.end(), ez.begin(), buffer.begin(),\n",
    "                 [](float x, float y) { return x - y; });\n",
    "\n",
    "  // FIXME(Step 1):\n",
    "  // compute transformation on GPU\n",
    "  std::transform(hx.begin(), hx.end() - n, buffer.begin(), hx.begin(),\n",
    "                 [dt, dx, dy](float h, float cex) {\n",
    "                   return h - dli::C0 * dt / 1.3f * cex / dy;\n",
    "                 });\n",
    "}\n",
    "\n",
    "// FIXME(Step 1):\n",
    "// accept device containers instead of `std::vector<float>`\n",
    "void update_hy(int n, float dx, float dy, float dt, std::vector<float> &hy,\n",
    "               std::vector<float> &ez, std::vector<float> &buffer) {\n",
    "  // FIXME(Step 2):\n",
    "  // Use zip and transform iterators to avoid materializing `ez[i] - ez[i + 1]`\n",
    "  // FIXME(Step 1):\n",
    "  // compute transformation on GPU\n",
    "  std::transform(ez.begin(), ez.end() - 1, ez.begin() + 1, buffer.begin(),\n",
    "                 [](float x, float y) { return x - y; });\n",
    "\n",
    "  // FIXME(Step 1):\n",
    "  // compute transformation on GPU\n",
    "  std::transform(hy.begin(), hy.end() - 1, buffer.begin(), hy.begin(),\n",
    "                 [dt, dx, dy](float h, float cey) {\n",
    "                   return h - dli::C0 * dt / 1.3f * cey / dx;\n",
    "                 });\n",
    "}\n",
    "\n",
    "// FIXME(Step 1):\n",
    "// accept device containers instead of `std::vector<float>`\n",
    "void update_dz(int n, float dx, float dy, float dt, std::vector<float> &hx_vec,\n",
    "               std::vector<float> &hy_vec, std::vector<float> &dz_vec,\n",
    "               std::vector<int> &cell_ids) {\n",
    "  auto hx = hx_vec.begin();\n",
    "  auto hy = hy_vec.begin();\n",
    "  auto dz = dz_vec.begin();\n",
    "\n",
    "  // FIXME(Step 1):\n",
    "  // compute for each on GPU\n",
    "  std::for_each(cell_ids.begin(), cell_ids.end(),\n",
    "                [n, dx, dy, dt, hx, hy, dz](int cell_id) {\n",
    "                  if (cell_id > n) {\n",
    "                    float hx_diff = hx[cell_id - n] - hx[cell_id];\n",
    "                    float hy_diff = hy[cell_id] - hy[cell_id - 1];\n",
    "                    dz[cell_id] += dli::C0 * dt * (hx_diff / dx + hy_diff / dy);\n",
    "                  }\n",
    "                });\n",
    "}\n",
    "\n",
    "// FIXME(Step 1):\n",
    "// accept device containers instead of `std::vector<float>`\n",
    "void update_ez(std::vector<float> &ez, std::vector<float> &dz) {\n",
    "  // FIXME(Step 1):\n",
    "  // compute transformation on GPU\n",
    "  std::transform(dz.begin(), dz.end(), ez.begin(),\n",
    "                 [](float d) { return d / 1.3f; });\n",
    "}\n",
    "\n",
    "// FIXME(Step 1):\n",
    "// remove this function\n",
    "std::vector<float> copy_to_host(const thrust::device_vector<float> &d_vec) {\n",
    "  std::vector<float> vec(d_vec.size());\n",
    "  thrust::copy(d_vec.begin(), d_vec.end(), vec.begin());\n",
    "  return vec;\n",
    "}\n",
    "\n",
    "// Do not change the signature of this function\n",
    "void simulate(int cells_along_dimension, float dx, float dy, float dt,\n",
    "              thrust::device_vector<float> &d_hx,\n",
    "              thrust::device_vector<float> &d_hy,\n",
    "              thrust::device_vector<float> &d_dz,\n",
    "              thrust::device_vector<float> &d_ez) {\n",
    "  // FIXME(Step 1):\n",
    "  // remove host containers and compute in the incoming device containers\n",
    "  std::vector<float> hx = copy_to_host(d_hx);\n",
    "  std::vector<float> hy = copy_to_host(d_hy);\n",
    "  std::vector<float> dz = copy_to_host(d_dz);\n",
    "  std::vector<float> ez = copy_to_host(d_ez);\n",
    "\n",
    "  // FIXME(Step 2):\n",
    "  // Remove `cell_ids` vector and use counting iterator instead\n",
    "  int cells = cells_along_dimension * cells_along_dimension;\n",
    "  std::vector<int> cell_ids(cells);\n",
    "  for (int i = 0; i < cells; i++) {\n",
    "    cell_ids[i] = i;\n",
    "  }\n",
    "\n",
    "  // FIXME(Step 2):\n",
    "  // Remove `buffer` vector and use fancy iterators instead\n",
    "  std::vector<float> buffer(cells);\n",
    "\n",
    "  for (int step = 0; step < dli::steps; step++) {\n",
    "    update_hx(cells_along_dimension, dx, dy, dt, hx, ez, buffer);\n",
    "    update_hy(cells_along_dimension, dx, dy, dt, hy, ez, buffer);\n",
    "    update_dz(cells_along_dimension, dx, dy, dt, hx, hy, dz, cell_ids);\n",
    "    update_ez(ez, dz);\n",
    "  }\n",
    "\n",
    "  // FIXME(Step 1):\n",
    "  // remove copy to host containers, compute in the incoming device containers\n",
    "  d_hx = hx;\n",
    "  d_hy = hy;\n",
    "  d_dz = dz;\n",
    "  d_ez = ez;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you address all `FIXME(Step 1)` comments, run the code cell below to see how your changes affect performance of the application.  \n",
    "The result will automatically be recorded for the autograder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not change this cell; results are recorded for the autograder\n",
    "Sources.dli.passes_step_1_with_n_of(1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Your Work\n",
    "Was the expected throughput achieved? \n",
    "Was the result still accurate? \n",
    "If not, try again until your code is fast enough and still correct. \n",
    "If your code passed, move on to the Step 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# Step 2: Accelerate the Simulator with Fancy Iterators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As written, the simulator is functional and GPU-accelerated, but it can be improved further.\n",
    "For instance, consider code below:\n",
    "\n",
    "```c++\n",
    "// Materialize `ez[i] - ez[i + 1]` in buffer\n",
    "std::transform(ez.begin(), ez.end() - 1, ez.begin() + 1, buffer.begin(),\n",
    "                [](float x, float y) { return x - y; });\n",
    "\n",
    "std::transform(hy.begin(), hy.end() - 1, buffer.begin(), hy.begin(),\n",
    "                [dt, dx, dy](float h, float cey) {\n",
    "                  return h - dli::C0 * dt / 1.3f * cey / dx;\n",
    "                });\n",
    "```\n",
    "\n",
    "We don't actually need data written to `buffer` to be materialized in memory.\n",
    "These are just temporary values that are used to compute `hy`.\n",
    "Besides that, there's a better way to provide cell indices to parallel algorithms than materializing them in memory:\n",
    "\n",
    "```cpp\n",
    "// Materialize cell indices (`i`) in memory\n",
    "std::vector<int> cell_ids(cells);\n",
    "for (int i = 0; i < cells; i++) {\n",
    "  cell_ids[i] = i;\n",
    "}\n",
    "```\n",
    "\n",
    "For this step, you'll have to remove any memory allocations from the code.\n",
    "Please copy your current solution from previous source or [Sources/maxwell.cu](Sources/maxwell.cu) into the following cell.\n",
    "Then, use counting, zip, and transform iterators instead of materialized vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Sources/maxwell.cu\n",
    "#include \"dli.h\"\n",
    "\n",
    "// 1. Copy content of the previous cell to this one \n",
    "// 2. Use counting, zip, and transform iterators instead of materialized vectors\n",
    "// 3. Run this cell to save the changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cell below to see how your changes affect performance of the application.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sources.dli.run_step_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you address all `FIXME(Step 2)` comments, run the code cell below to see how your changes affect performance of the application.\n",
    "The result will automatically be recorded for the autograder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not change this cell; results are recorded for the autograder\n",
    "Sources.dli.passes_step_2_with_n_of(1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Your Work\n",
    "Was the expected throughput achieved? Was the result still accurate? \n",
    "If not, try again until your code is fast enough and still correct. \n",
    "If your code passed, move on to the Step 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# Step 3: Coarse Grid with CUDA Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, our simulator is writing data to disk at the resolution of compute steps. \n",
    "We don't need such a fine resolution to visualize the results.\n",
    "As part of this step, we'll try to coarse the grid.\n",
    "\n",
    "<img src=\"Images/coarsening.png\" alt=\"Coarsening\" width=900>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll split the grid into 2D tiles and compute the average value of each tile.\n",
    "For this step, please edit the cell below.\n",
    "This cell already contains a CUDA kernel that assigns one thread block to one coarse tile.\n",
    "Each thread has one value from the fine tile, which is already loaded for you:\n",
    "\n",
    "```c++\n",
    "float thread_value = fine(fine_row, fine_col);\n",
    "```\n",
    "\n",
    "Use `cub::BlockReduce` to compute the average value of all `thread_value`s in a given thread block and write the result into the coarse grid:\n",
    "```c++\n",
    "coarse(coarse_row, coarse_col) = block_average;\n",
    "```\n",
    "\n",
    "Note that `cub::BlockReduce` only returns a valid result in the first thread of the block.\n",
    "\n",
    "<img src=\"Images/coop-reduce.png\" alt=\"Reduce\" width=600>\n",
    "\n",
    "If you want to start again, just copy the backup source [Backup/coarse.cu](Backup/coarse.cu).\n",
    "\n",
    "<details>\n",
    "<summary>Original code in case you need it</summary>\n",
    "\n",
    "```c++\n",
    "%%writefile Sources/coarse.cu\n",
    "#include \"dli.h\"\n",
    "\n",
    "__global__ void kernel(dli::temperature_grid_f fine,\n",
    "                       dli::temperature_grid_f coarse) {\n",
    "  int coarse_row = blockIdx.x / coarse.extent(1);\n",
    "  int coarse_col = blockIdx.x % coarse.extent(1);\n",
    "  int row = threadIdx.x / dli::tile_size;\n",
    "  int col = threadIdx.x % dli::tile_size;\n",
    "  int fine_row = coarse_row * dli::tile_size + row;\n",
    "  int fine_col = coarse_col * dli::tile_size + col;\n",
    "\n",
    "  float thread_value = fine(fine_row, fine_col);\n",
    "\n",
    "  // FIXME(Step 3):\n",
    "  // Compute the sum of `thread_value` across threads of a thread block\n",
    "  // using `cub::BlockReduce`\n",
    "  float block_sum = ...;\n",
    "\n",
    "  // FIXME(Step 3):\n",
    "  // `cub::BlockReduce` returns block sum in thread 0, make sure to write\n",
    "  // result only from the first thread of the block\n",
    "  coarse(coarse_row, coarse_col) = block_average;\n",
    "}\n",
    "\n",
    "// Don't change the signature of this function\n",
    "void coarse(dli::temperature_grid_f fine, dli::temperature_grid_f coarse) {\n",
    "  kernel<<<coarse.size(), dli::block_threads>>>(fine, coarse);\n",
    "}\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Sources/coarse.cu\n",
    "#include \"dli.h\"\n",
    "\n",
    "__global__ void kernel(dli::temperature_grid_f fine,\n",
    "                       dli::temperature_grid_f coarse) {\n",
    "  int coarse_row = blockIdx.x / coarse.extent(1);\n",
    "  int coarse_col = blockIdx.x % coarse.extent(1);\n",
    "  int row = threadIdx.x / dli::tile_size;\n",
    "  int col = threadIdx.x % dli::tile_size;\n",
    "  int fine_row = coarse_row * dli::tile_size + row;\n",
    "  int fine_col = coarse_col * dli::tile_size + col;\n",
    "\n",
    "  float thread_value = fine(fine_row, fine_col);\n",
    "\n",
    "  // FIXME(Step 3):\n",
    "  // Compute the sum of `thread_value` across threads of a thread block\n",
    "  // using `cub::BlockReduce`\n",
    "  float block_sum = ...;\n",
    "\n",
    "  // FIXME(Step 3):\n",
    "  // `cub::BlockReduce` returns block sum in thread 0, make sure to write\n",
    "  // result only from the first thread of the block\n",
    "  coarse(coarse_row, coarse_col) = block_average;\n",
    "}\n",
    "\n",
    "// Don't change the signature of this function\n",
    "void coarse(dli::temperature_grid_f fine, dli::temperature_grid_f coarse) {\n",
    "  kernel<<<coarse.size(), dli::block_threads>>>(fine, coarse);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you are done modifying the code, run the code cell below to see how your changes affect data that is stored to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sources.dli.run_step_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the code is running error-free and you are seeing the visualization, run the code cell below to see how your changes affect performance and accuracy of the application.  \n",
    "The result will automatically be recorded for the autograder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not change this cell; results are recorded for the autograder\n",
    "Sources.dli.passes_step_3_with_n_of(1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Your Work\n",
    "Was the expected throughput achieved? Was the result still accurate?  If not, try again until your code is fast enough and still correct.\n",
    "If your code passed, move on to the submission step. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# Step 4: Submit Your Assessment\n",
    "\n",
    "If you are satisfied that you have completed the steps correctly, it is time to submit your project as follows to the autograder:\n",
    "\n",
    "1. Go back to the DLI course GPU launch page and click the checkmark to run the assessment:\n",
    "\n",
    "<img src=\"Images/assessment_checkmark.png\">\n",
    "\n",
    "2. That's it!  You'll receive a pop-up window with the grading feedback, and the points will be credited to your progress. \n",
    "\n",
    "<img src=\"Images/assessment_pass_popup.png\">\n",
    "\n",
    "You can always check your grade in the course progress tab.  Note that partial values for the coding assessment won't be visible here - it shows up as either 0 or 100 points. \n",
    "\n",
    "<img src=\"Images/progress.png\">\n",
    "\n",
    " Once you've passed this assessment, you can find your certificate on the `My Learning` page, linked in the dropdown menu of your account.\n",
    "\n",
    " <img src=\"Images/dli_dropdown.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"Images/nvidia_header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
