{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/nvidia_header.png\" style=\"margin-left: -30px; width: 300px; float: left;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Async Copy and Streams\n",
    "\n",
    "Usage of streams:\n",
    "\n",
    "```c++\n",
    "cudaStream_t stream;\n",
    "\n",
    "// create a stream\n",
    "cudaStreamCreate(&stream); \n",
    "\n",
    "// make CPU wait for all operations in the stream to complete\n",
    "cudaStreamSynchronize(stream); \n",
    "\n",
    "// destroy the stream\n",
    "cudaStreamDestroy(stream);\n",
    "```\n",
    "\n",
    "Usage of `cub::DeviceTransform`:\n",
    "\n",
    "```c++\n",
    "cub::DeviceTransform::Transform(input_iterator, output_iterator, num_items, op, stream);\n",
    "```\n",
    "\n",
    "Usage of `cudaMemcpyAsync`:\n",
    "\n",
    "```c++\n",
    "cudaMemcpyAsync(dst, src, num_bytes, cudaMemcpyDeviceToHost, stream);\n",
    "```\n",
    "\n",
    "For this exercise, we'll attempt to make transfers between the host and device asynchronous.\n",
    "To do this, you are expected to:\n",
    "\n",
    "- replace `thrust::copy` with `cudaMemcpyAsync`\n",
    "- put compute and copy operations in separate CUDA streams\n",
    "- synchronize the streams to follow the pattern from the diagram below\n",
    "\n",
    "<img src=\"Images/async-copy.png\" alt=\"Compute/Copy Overlap\" width=900>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Sources/async-copy.cu\n",
    "#include \"dli.h\"\n",
    "\n",
    "void simulate(int width, int height, const thrust::device_vector<float> &in,\n",
    "              thrust::device_vector<float> &out, \n",
    "              cudaStream_t stream = 0) \n",
    "{\n",
    "  cuda::std::mdspan temp_in(thrust::raw_pointer_cast(in.data()), height, width);\n",
    "  cub::DeviceTransform::Transform(\n",
    "      thrust::make_counting_iterator(0), out.begin(), width * height,\n",
    "      [=] __host__ __device__(int id) { return dli::compute(id, temp_in); },\n",
    "      stream);\n",
    "}\n",
    "\n",
    "int main() \n",
    "{\n",
    "  int height = 2048;\n",
    "  int width = 8192;\n",
    "\n",
    "  thrust::device_vector<float> d_prev = dli::init(height, width);\n",
    "  thrust::device_vector<float> d_next(height * width);\n",
    "  thrust::device_vector<float> d_buffer(height * width);\n",
    "  thrust::host_vector<float> h_prev(height * width);\n",
    "\n",
    "  const int compute_steps = 750;\n",
    "  const int write_steps = 3;\n",
    "\n",
    "  // 1. Create compute and copy streams\n",
    "\n",
    "  for (int write_step = 0; write_step < write_steps; write_step++) \n",
    "  {\n",
    "    thrust::copy(d_prev.begin(), d_prev.end(), d_buffer.begin());\n",
    "\n",
    "    // 2. Replace `thrust::copy` with `cudaMemcpyAsync` on copy stream.\n",
    "    //    Use `thrust::raw_pointer_cast(vec.data())` to get raw pointers from Thrust containers.\n",
    "    thrust::copy(d_buffer.begin(), d_buffer.end(), h_prev.begin());\n",
    "\n",
    "    for (int compute_step = 0; compute_step < compute_steps; compute_step++) \n",
    "    {\n",
    "      // 3. Put `simulate` on compute stream\n",
    "      simulate(width, height, d_prev, d_next);\n",
    "      d_prev.swap(d_next);\n",
    "    }\n",
    "\n",
    "    // 4. Make sure to synchronize copy stream before reading `h_prev`\n",
    "    dli::store(write_step, height, width, h_prev);\n",
    "\n",
    "    // 5. Make sure to synchronize compute stream before next iteration\n",
    "    cudaDeviceSynchronize(); \n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc --extended-lambda -o /tmp/a.out Sources/async-copy.cu # build executable\n",
    "!nsys profile --force-overwrite true -o ../nsight-reports/copy /tmp/a.out # run and profile executable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you’re unsure how to proceed, consider expanding this section for guidance. Use the hint only after giving the problem a genuine attempt.\n",
    "\n",
    "<details>\n",
    "  <summary>Hints</summary>\n",
    "  \n",
    "  - CUB accepts `stream` as its last argument `cub::DeviceTransform::Transform(input, output, num_items, op, stream)` \n",
    "  - `cudaMemcpyAsync` accepts `stream` as its last argument `cudaMemcpyAsync(dst, src, size, cudaMemcpyDeviceToHost, stream)`\n",
    "  - You can use the following operations on a CUDA stream:\n",
    "    - `cudaStreamCreate(&stream)` to create a stream\n",
    "    - `cudaStreamDestroy(stream)` to destroy a stream\n",
    "    - `cudaStreamSynchronize(stream)` to make the CPU wait for `stream` to finish all operations\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open this section only after you’ve made a serious attempt at solving the problem. Once you’ve completed your solution, compare it with the reference provided here to evaluate your approach and identify any potential improvements.\n",
    "\n",
    "<details>\n",
    "  <summary>Solution</summary>\n",
    "\n",
    "  Key points:\n",
    "\n",
    "  - Synchronize the copy stream before storing the data\n",
    "\n",
    "  Solution:\n",
    "  ```c++\n",
    "  cudaStream_t compute_stream;\n",
    "  cudaStreamCreate(&compute_stream);\n",
    "\n",
    "  cudaStream_t copy_stream;\n",
    "  cudaStreamCreate(&copy_stream);\n",
    "\n",
    "  for (int write_step = 0; write_step < write_steps; write_step++) \n",
    "  {\n",
    "    cudaMemcpy(thrust::raw_pointer_cast(d_buffer.data()),\n",
    "               thrust::raw_pointer_cast(d_prev.data()),\n",
    "               height * width * sizeof(float), cudaMemcpyDeviceToDevice);\n",
    "    cudaMemcpyAsync(thrust::raw_pointer_cast(h_temp.data()),\n",
    "                    thrust::raw_pointer_cast(d_buffer.data()),\n",
    "                    height * width * sizeof(float), cudaMemcpyDeviceToHost,\n",
    "                    copy_stream);\n",
    "\n",
    "    for (int compute_step = 0; compute_step < compute_steps; compute_step++) {\n",
    "      simulate(width, height, d_prev, d_next, compute_stream);\n",
    "      d_prev.swap(d_next);\n",
    "    }\n",
    "\n",
    "    cudaStreamSynchronize(copy_stream);\n",
    "    dli::store(write_step, height, width, h_temp);\n",
    "\n",
    "    cudaStreamSynchronize(compute_stream);\n",
    "  }\n",
    "\n",
    "  cudaStreamDestroy(compute_stream);\n",
    "  cudaStreamDestroy(copy_stream);\n",
    "  ```\n",
    "\n",
    "  You can find the full solution [here](Solutions/async-copy.cu).\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Great job!  Proceed to the [next section](../02.04-Pinned-Memory/02.04.01-Pinned.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/nvidia_header.png\" style=\"margin-left: -30px; width: 300px; float: left;\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
