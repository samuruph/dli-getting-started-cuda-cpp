WEBVTT

00:00:01.041 --> 00:00:03.973
So far, we've looked at simple
temperature simulations where

00:00:03.983 --> 00:00:08.092
each cell or object evolved on
its own, independent of the others.

00:00:08.146 --> 00:00:10.311
Of course, that
isn't very realistic.

00:00:10.368 --> 00:00:12.890
Now that we're comfortable
with fancy iterators, parallel

00:00:12.950 --> 00:00:16.072
algorithms, and execution
spaces, let's tackle a slightly

00:00:16.112 --> 00:00:19.612
more complex scenario, the
2D heat equation.

00:00:19.695 --> 00:00:21.516
This illustration
shows the computational

00:00:21.576 --> 00:00:23.465
stencil that we'll use.

00:00:23.557 --> 00:00:26.004
Each cell's temperature in
the next time step

00:00:26.038 --> 00:00:29.305
Depends not only on its
current temperature, but

00:00:29.321 --> 00:00:34.278
also on its four neighbors,
left, right, top, and bottom.

00:00:34.427 --> 00:00:38.202
In code, the 2D heat equation
might look something like this.

00:00:38.251 --> 00:00:41.521
Don't worry about the specific
math or constants here.

00:00:41.574 --> 00:00:45.515
Instead, try focusing on the
data access pattern.

00:00:45.638 --> 00:00:48.101
First, we read temperature
from the left and right

00:00:48.161 --> 00:00:49.986
neighbors of a given cell.

00:00:50.054 --> 00:00:54.215
A 2D array is typically laid out in
row-major order, meaning each row

00:00:54.275 --> 00:00:56.343
is placed sequentially in memory.

00:00:56.396 --> 00:01:00.858
To find a flattened 1D index
of a 2D row-column index,

00:01:00.897 --> 00:01:04.577
we can multiply the row index
by the width of our grid and

00:01:04.617 --> 00:01:07.066
then add the column index.

00:01:07.158 --> 00:01:11.637
Row times width jumps us to the
start of the correct row, because

00:01:11.659 --> 00:01:14.352
each row has width elements.

00:01:14.420 --> 00:01:18.141
Adding column then offsets
us within that row, taking

00:01:18.201 --> 00:01:20.376
us to the specific column.

00:01:20.447 --> 00:01:23.365
Using the same pattern, if
we went to the left neighbor

00:01:23.390 --> 00:01:27.271
of a given cell, we just subtract
one from the column index.

00:01:27.313 --> 00:01:30.613
For the right neighbor,
we add one instead.

00:01:30.756 --> 00:01:33.779
Similarly, we compute the
indices of top and bottom

00:01:33.819 --> 00:01:38.976
neighbors by subtracting and adding
one to the current row index.

00:01:39.143 --> 00:01:41.225
Besides that, we
incorporate the previous

00:01:41.265 --> 00:01:42.910
temperature of a given cell.

00:01:42.947 --> 00:01:47.423
This code works fine in most of
the cases, but there's one issue.

00:01:47.523 --> 00:01:50.744
Real grids aren't infinite,
so cells along the edges don't

00:01:50.804 --> 00:01:52.755
have all four neighbors.

00:01:52.825 --> 00:01:55.807
If we tried to compute the left
neighbor for the leftmost cell,

00:01:55.847 --> 00:01:58.020
for example, we'd go out of bounds.

00:01:58.068 --> 00:02:00.991
To prevent that, we need to
handle boundary conditions.

00:02:01.029 --> 00:02:04.406
In this course, we're using
constant boundary conditions.

00:02:04.451 --> 00:02:08.296
This means that we won't update
the temperature for boundary cells.

00:02:08.352 --> 00:02:11.338
They keep their original values.

00:02:11.528 --> 00:02:13.909
The next question is how
we actually launch this

00:02:13.969 --> 00:02:16.276
computation on our 2D data.

00:02:16.331 --> 00:02:19.152
If you think about it, each
cell in our grid corresponds

00:02:19.192 --> 00:02:22.878
to a single ID in a flattened
one-dimensional space.

00:02:22.954 --> 00:02:26.236
So we can just use the thrust
Make Counting Iterator to

00:02:26.276 --> 00:02:30.622
generate all possible cell
IDs and then transform those IDs

00:02:30.638 --> 00:02:33.497
into updated temperature values.

00:02:33.600 --> 00:02:36.341
But we still need to figure
out which row and column these

00:02:36.381 --> 00:02:38.234
flat IDs correspond to.

00:02:38.305 --> 00:02:41.066
We use division and modulus
to reverse the process we

00:02:41.166 --> 00:02:42.766
use to flatten the matrix.

00:02:42.806 --> 00:02:47.759
This way we can map each flat index
back to its correct 2D position.

00:02:47.867 --> 00:02:50.208
After that, the rest of the
code has the same boundary

00:02:50.248 --> 00:02:52.448
check logic that we used before.

00:02:52.528 --> 00:02:56.395
Essentially, we're just
transforming cell IDs into

00:02:56.429 --> 00:02:59.710
next state temperatures
without needing an explicit

00:02:59.770 --> 00:03:03.470
loop over rows and columns.

00:03:04.056 --> 00:03:07.077
Notice that we're capturing
the pointer to our temperature

00:03:07.117 --> 00:03:10.047
data in a slightly unusual way.

00:03:10.137 --> 00:03:15.474
In standard C++, calling data
on an std vector returns a

00:03:15.498 --> 00:03:21.437
raw pointer, but with Thrust
containers, data returns a typed

00:03:21.459 --> 00:03:23.876
iterator instead of a raw pointer.

00:03:23.960 --> 00:03:28.141
Thrust needs that type information
for various reasons, which

00:03:28.221 --> 00:03:29.924
we'll explore later.

00:03:30.014 --> 00:03:33.564
For now, the main point is
that you can convert this typed

00:03:33.576 --> 00:03:40.370
iterator to a regular C++ pointer
by using thrust raw pointer cast.

00:03:40.480 --> 00:03:44.563
This gives us the in-pointer
variable that we can

00:03:44.643 --> 00:03:48.030
capture in the lambda.

00:03:48.245 --> 00:03:51.783
We can start by initializing
the entire grid to a low,

00:03:51.807 --> 00:03:56.092
uniform temperature, and then set
at some higher temperature values

00:03:56.110 --> 00:03:58.799
at the top and bottom boundaries.

00:03:58.891 --> 00:04:01.761
If we run our heat equation
transformation with those

00:04:01.773 --> 00:04:06.709
initial conditions, we get results
that look a bit like an empty oven

00:04:06.755 --> 00:04:09.947
heating from the top and bottom.

00:04:10.057 --> 00:04:14.407
Over time, you can see the heat
spreading into the cooler regions,

00:04:14.480 --> 00:04:18.311
all according to the stencil
computations we just set up.

00:04:18.442 --> 00:04:21.463
An important thing to remember
is that Thrust isn't limited

00:04:21.523 --> 00:04:24.505
to algorithms that match the
The exact signatures of the

00:04:24.565 --> 00:04:27.004
C++ standard library.

00:04:27.102 --> 00:04:29.983
If there's a common pattern
that can be accelerated on

00:04:30.023 --> 00:04:34.912
the GPU, Thrust often provides
a specialized algorithm for it.

00:04:34.984 --> 00:04:37.605
A good example is Thrust Tabulate.

00:04:37.665 --> 00:04:41.106
Under the hood, it's really
just transforming a counting

00:04:41.186 --> 00:04:44.555
iterator, something which
we've seen is quite common.

00:04:44.567 --> 00:04:47.768
So Thrust gives it a dedicated
name and interface.

00:04:47.828 --> 00:04:51.809
The call looks just like Thrust
Transform, except that there's

00:04:51.869 --> 00:04:55.256
no input range to pass in
Because the input is implicitly

00:04:55.270 --> 00:04:57.576
generated by tabulation.

00:04:57.657 --> 00:05:00.778
Besides being more convenient,
specialized algorithms like

00:05:00.838 --> 00:05:02.876
this are often more optimized.

00:05:02.918 --> 00:05:06.058
So if you spot an algorithm
whose name and purpose match

00:05:06.118 --> 00:05:10.253
what you need to do, it's
a good idea to use it.

00:05:10.419 --> 00:05:13.160
Let's take that next step
and replace Thrust Transform

00:05:13.180 --> 00:05:14.648
with Thrust Tabulate.

00:05:14.700 --> 00:05:17.626
Notice we don't need to create
a counting iterator anymore.

00:05:17.640 --> 00:05:20.315
Tabulate generates the
indices internally.

00:05:20.381 --> 00:05:22.581
The rest of the code stays
exactly the same, so it's

00:05:22.621 --> 00:05:23.963
a straightforward swap.

00:05:24.001 --> 00:05:28.551
This makes our intent clearer
and code easier to read.

00:05:28.732 --> 00:05:32.295
We'll likely need to convert from
the flat 1D index to 2D coordinates

00:05:32.355 --> 00:05:35.958
in more than one place, so
it's best to follow the dry, don't

00:05:35.998 --> 00:05:40.145
repeat yourself principle and put
the logic in a separate function.

00:05:40.182 --> 00:05:42.701
That's what the row call
function does here.

00:05:42.744 --> 00:05:46.537
It returns a standard pair of
the row and column calculated

00:05:46.547 --> 00:05:48.994
from the flat ID and grid width.

00:05:49.089 --> 00:05:53.052
We've marked this function as
host device so that it can be

00:05:53.112 --> 00:05:56.627
called by both the CPU and the GPU.

00:05:56.704 --> 00:05:59.645
Then, in our lambda, we can
use structured bindings to

00:05:59.725 --> 00:06:03.330
unpack the pair directly into
row and column variables.

00:06:03.426 --> 00:06:06.671
This keeps our code clean,
makes it easier to maintain,

00:06:06.707 --> 00:06:11.026
and avoids scattering the
same formula in multiple places.

00:06:11.208 --> 00:06:14.269
Unfortunately, the C++ standard
library doesn't know anything

00:06:14.329 --> 00:06:17.990
about CUDA, so functions
like std makepair aren't

00:06:18.070 --> 00:06:20.141
marked as host device.

00:06:20.211 --> 00:06:24.088
Calling them inside device code
triggers a compilation error.

00:06:24.144 --> 00:06:27.266
Like the one shown here, calling
a host function from a host

00:06:27.306 --> 00:06:29.471
device function is not allowed.

00:06:29.527 --> 00:06:31.843
So what are our options here?

00:06:31.889 --> 00:06:35.119
Do we have to re-implement
every standard library type

00:06:35.131 --> 00:06:38.772
just to make it device friendly?

00:06:39.462 --> 00:06:41.695
Unfortunately, we
don't have to do that.

00:06:41.746 --> 00:06:48.455
Recall from the stack diagram that
THRUST is built on top of LIBQ++.

00:06:51.930 --> 00:06:54.181
Fortunately, we
don't have to do that.

00:06:54.232 --> 00:06:57.334
Recall from the stack diagram
that Thrust is built on top

00:06:57.394 --> 00:07:01.747
of libq++, a core library
that provides host-device-friendly

00:07:01.757 --> 00:07:06.162
implementations of many standard
C++ vocabulary types.

00:07:06.240 --> 00:07:10.063
For instance, it provides
types as pair, tuple, optional,

00:07:10.123 --> 00:07:12.812
variant, complex, and atomic.

00:07:12.905 --> 00:07:15.847
Not only do these types
carry the proper host-device

00:07:15.927 --> 00:07:20.373
annotations, but they're
also optimized for GPU usage.

00:07:20.458 --> 00:07:23.940
That means you can treat them as
drop-in replacements for the usual

00:07:24.000 --> 00:07:29.474
C++ types, and they'll compile and
run correctly on both CPU and GPU.

00:07:29.543 --> 00:07:35.515
Let's see how to swap out std
pair for the libq++ equivalent.

00:07:35.666 --> 00:07:37.887
The actual change
couldn't be simpler.

00:07:37.927 --> 00:07:42.991
We just prefix CUDA to std
pair, making it CUDA std pair.

00:07:43.050 --> 00:07:45.789
And now our code compiles
and runs without issues.

00:07:45.834 --> 00:07:48.976
The same pattern applies to
other standard library types.

00:07:49.016 --> 00:07:53.099
Just pull them in through CUDA STD
instead of STD, and you'll have

00:07:53.179 --> 00:07:56.526
GPU-friendly optimized equivalents.

00:07:56.641 --> 00:08:00.669
CUDA STD pair isn't the only
type that can clean up our code.

00:08:00.723 --> 00:08:04.726
Right now, we're still manually
converting between 2D row-column

00:08:04.766 --> 00:08:07.373
coordinates and the 1D indices.

00:08:07.448 --> 00:08:11.326
That approach works, but it's
easy to make off-by-one mistakes

00:08:11.350 --> 00:08:12.990
and other indexing errors.

00:08:13.035 --> 00:08:14.376
It's also not very expressive.

00:08:14.456 --> 00:08:17.257
You have to remember the
exact formula for flattening

00:08:17.297 --> 00:08:19.390
coordinates every time.

00:08:19.499 --> 00:08:22.898
It might not be too bad when we're
just flattening two dimensions,

00:08:22.941 --> 00:08:26.853
but as soon as you go beyond
that, things get ugly quickly.

00:08:26.923 --> 00:08:28.146
Take a look at this snippet.

00:08:28.164 --> 00:08:32.344
It flattens a five-dimensional set
of coordinates into a single index.

00:08:32.406 --> 00:08:34.980
It's easy to make a mistake
in code like this.

00:08:35.008 --> 00:08:37.589
It even includes a comment
to show what the actual

00:08:37.649 --> 00:08:39.663
intended indexing is.

00:08:39.747 --> 00:08:43.509
Wouldn't it be nice to use a
standard C++ type that could

00:08:43.569 --> 00:08:47.958
make this type of indexing
actually compile?

00:08:48.131 --> 00:08:53.283
CUDA std mdspan is a non-owning
multi-dimensional view built

00:08:53.293 --> 00:08:55.870
on top of a flat data array.

00:08:55.954 --> 00:08:59.427
Think of it like a lightweight
wrapper around your memory.

00:08:59.516 --> 00:09:04.058
You give mdspan the dimensions,
for example, height and width in

00:09:04.098 --> 00:09:09.736
the 2D case, and it automatically
handles the offset calculations.

00:09:09.861 --> 00:09:13.450
Because it's just a view, there's
no extra memory or hidden overhead.

00:09:13.464 --> 00:09:15.690
It's practically zero cost.

00:09:15.766 --> 00:09:19.753
Using MD-SPAN results in cleaner
code and fewer bugs.

00:09:19.850 --> 00:09:24.212
The illustration here shows
how a 1D array of six elements

00:09:24.254 --> 00:09:29.186
can be treated as a three
by two grid through MD-SPAN.

00:09:29.339 --> 00:09:31.908
Because MD-SPAN doesn't own memory,

00:09:31.960 --> 00:09:35.753
You need an underlying buffer
that holds the actual data.

00:09:35.844 --> 00:09:39.567
In this example, we've created a
CUDA STD array of six integers,

00:09:39.567 --> 00:09:44.894
0, 1, 2, 3, 4, and 5. mdspan
will then view these values

00:09:44.912 --> 00:09:49.757
in whichever multidimensional shape
we specify, but the data itself

00:09:49.837 --> 00:09:52.649
remains right here in our array.

00:09:52.780 --> 00:09:56.841
Let's construct an mdspan
based on this array.

00:09:56.923 --> 00:10:00.543
For this case, we have to
pass mdspan three things.

00:10:00.586 --> 00:10:03.661
First, we need a raw
pointer to the data.

00:10:03.728 --> 00:10:06.630
Here we use the array.data
member function, which

00:10:06.670 --> 00:10:08.619
returns a raw pointer.

00:10:08.671 --> 00:10:11.814
Remember though, if you have
to construct mdspan on top

00:10:11.834 --> 00:10:16.168
of a thrust container, you'll
need to use raw pointer cast.

00:10:16.237 --> 00:10:18.759
Besides the raw pointer, we'll
have to provide the number

00:10:18.779 --> 00:10:20.447
of rows and columns.

00:10:20.520 --> 00:10:23.682
That's all mdspan needs
to treat our 1D array as

00:10:23.742 --> 00:10:26.863
a two by three matrix.

00:10:27.250 --> 00:10:30.172
Once the MD-SPAN is set up,
you can access the underlying

00:10:30.212 --> 00:10:32.339
sequence using parentheses.

00:10:32.433 --> 00:10:35.899
Just supply the row and column
indices, starting with 0.

00:10:35.915 --> 00:10:41.139
For example, passing MD parentheses
1, 2 returns the element of

00:10:41.179 --> 00:10:45.773
the second row, third column,
so a value of 5 in our case.

00:10:45.842 --> 00:10:49.144
Besides the direct element
access, MD-SPAN also provides

00:10:49.184 --> 00:10:50.890
some handy helper functions.

00:10:50.945 --> 00:10:53.470
For instance, calling MD size

00:10:53.533 --> 00:10:56.240
Returns the total number of
elements in the view.

00:10:56.276 --> 00:11:00.099
In this example, that would be six.

00:11:00.720 --> 00:11:03.403
Additionally, mdspan lets
you query the size of each

00:11:03.443 --> 00:11:06.387
dimension using the extent method.

00:11:06.465 --> 00:11:10.895
For a two-dimensional view, calling
mdextent 0 gives you the height

00:11:10.930 --> 00:11:14.136
and mdextent 1 gives you the width.

00:11:14.193 --> 00:11:17.682
In this example, mdextent
0 will return 2 and

00:11:17.696 --> 00:11:20.063
mdextent 1 will return 3.

00:11:20.118 --> 00:11:23.061
This is essentially the order
at which we provided these

00:11:23.121 --> 00:11:25.744
values in the constructor.

00:11:25.902 --> 00:11:29.526
For the exercise in this section,
instead of capturing a raw

00:11:29.586 --> 00:11:33.470
pointer in our lambda, we'll
capture an empty span.

00:11:33.531 --> 00:11:37.147
That way we can use
multidimensional indexing directly

00:11:37.175 --> 00:11:42.208
without manually flattening the
row and column into a single index.

00:11:42.381 --> 00:11:45.024
It'll make the code cleaner
and less error prone while

00:11:45.064 --> 00:11:46.606
maintaining the same performance.

