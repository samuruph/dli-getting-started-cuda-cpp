{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/nvidia_header.png\" style=\"margin-left: -30px; width: 300px; float: left;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing New Algorithms with CUDA Kernels\n",
    "\n",
    "In this lab, you learned some options for handling situations where  there’s no parallel algorithm for your specific use case, or you can’t adapt existing ones with fancy iterators."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "The key takeaways from this lab were:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write custom CUDA kernels only when your use case is not covered by existing accelerated libraries.\n",
    "\n",
    "<img src=\"Images/takeaway_3_1.png\" alt=\"kernels\" width=600>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use syncthreads to avoid data races within a thread block\n",
    "\n",
    "<img src=\"Images/takeaway_3_2.png\" alt=\"syncthreads\" width=600>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use shared:\n",
    "- **When you need a temporary storage inside a thread block**\n",
    "- **When you need to exchange data between threads of a thread block**\n",
    "- **When your data is not efficiently cached by L1**\n",
    "- \n",
    "<img src=\"Images/takeaway_3_3.png\" alt=\"shared\" width=600>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use device-side libraries:\n",
    "- **CUB for block, and warp-scope cooperative general-purpose algorithms**\n",
    "- **libcudacxx for vocabulary types**\n",
    "- **cuBLASDx for linear algebra**\n",
    "- **cuFFTDx for FFT**\n",
    "- **and so on...**\n",
    "\n",
    "<img src=\"Images/takeaway_3_4.png\" alt=\"libs\" width=600>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use developer tools:\n",
    "- **compute-sanitizer for CUDA kernels correctness checking** \n",
    "- **cuda-gdb for CUDA kernels debugging**\n",
    "- **NVIDIA Nsight Systems to identify  bottlenecks in your application**\n",
    "- **NVIDIA Nsight Compute for in-depth kernel profiling**\n",
    "\n",
    "<img src=\"Images/takeaway_3_5.png\" alt=\"dev tools\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "When you are ready, move on to the [assessment](../04.01-Assessment/assessment.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/nvidia_header.png\" style=\"margin-left: -30px; width: 300px; float: left;\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
