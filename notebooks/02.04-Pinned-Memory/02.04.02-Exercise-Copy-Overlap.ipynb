{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/nvidia_header.png\" style=\"margin-left: -30px; width: 300px; float: left;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Async Copy and Pinned Memory\n",
    "\n",
    "For this exercise, we'll attempt to fix our program to make the copy actually asynchronous.\n",
    "To do this, you are expected to:\n",
    "\n",
    "- Use `thrust::universal_host_pinned_vector` to allocate pinned memory for the host buffer\n",
    "- Profile the program to see if the copy becomes asynchronous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Copy of the original code if you need to refer to it.</summary>\n",
    "\n",
    "```c++\n",
    "%%writefile Sources/copy-overlap.cu\n",
    "#include \"dli.h\"\n",
    "\n",
    "int main() \n",
    "{\n",
    "  int height = 2048;\n",
    "  int width = 8192;\n",
    "\n",
    "  cudaStream_t compute_stream;\n",
    "  cudaStreamCreate(&compute_stream);\n",
    "\n",
    "  cudaStream_t copy_stream;\n",
    "  cudaStreamCreate(&copy_stream);\n",
    "\n",
    "  thrust::device_vector<float> d_prev = dli::init(height, width);\n",
    "  thrust::device_vector<float> d_next(height * width);\n",
    "  thrust::device_vector<float> d_buffer(height * width);\n",
    "\n",
    "  // 1. Change code below to allocate host vector in pinned memory\n",
    "  thrust::host_vector<float> h_prev(height * width);\n",
    "\n",
    "  const int compute_steps = 750;\n",
    "  const int write_steps = 3;\n",
    "  for (int write_step = 0; write_step < write_steps; write_step++) \n",
    "  {\n",
    "    cudaMemcpy(thrust::raw_pointer_cast(d_buffer.data()),\n",
    "               thrust::raw_pointer_cast(d_prev.data()),\n",
    "               height * width * sizeof(float), cudaMemcpyDeviceToDevice);\n",
    "    cudaMemcpyAsync(thrust::raw_pointer_cast(h_prev.data()),\n",
    "                    thrust::raw_pointer_cast(d_buffer.data()),\n",
    "                    height * width * sizeof(float), cudaMemcpyDeviceToHost,\n",
    "                    copy_stream);\n",
    "\n",
    "    for (int compute_step = 0; compute_step < compute_steps; compute_step++) \n",
    "    {\n",
    "      dli::simulate(width, height, d_prev, d_next, compute_stream);\n",
    "      d_prev.swap(d_next);\n",
    "    }\n",
    "\n",
    "    cudaStreamSynchronize(copy_stream);\n",
    "    dli::store(write_step, height, width, h_prev);\n",
    "\n",
    "    cudaStreamSynchronize(compute_stream);\n",
    "  }\n",
    "\n",
    "  cudaStreamDestroy(compute_stream);\n",
    "  cudaStreamDestroy(copy_stream);\n",
    "}\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Sources/copy-overlap.cu\n",
    "#include \"dli.h\"\n",
    "\n",
    "int main() \n",
    "{\n",
    "  int height = 2048;\n",
    "  int width = 8192;\n",
    "\n",
    "  cudaStream_t compute_stream;\n",
    "  cudaStreamCreate(&compute_stream);\n",
    "\n",
    "  cudaStream_t copy_stream;\n",
    "  cudaStreamCreate(&copy_stream);\n",
    "\n",
    "  thrust::device_vector<float> d_prev = dli::init(height, width);\n",
    "  thrust::device_vector<float> d_next(height * width);\n",
    "  thrust::device_vector<float> d_buffer(height * width);\n",
    "\n",
    "  // 1. Change code below to allocate host vector in pinned memory\n",
    "  thrust::host_vector<float> h_prev(height * width);\n",
    "\n",
    "  const int compute_steps = 750;\n",
    "  const int write_steps = 3;\n",
    "  for (int write_step = 0; write_step < write_steps; write_step++) \n",
    "  {\n",
    "    cudaMemcpy(thrust::raw_pointer_cast(d_buffer.data()),\n",
    "               thrust::raw_pointer_cast(d_prev.data()),\n",
    "               height * width * sizeof(float), cudaMemcpyDeviceToDevice);\n",
    "    cudaMemcpyAsync(thrust::raw_pointer_cast(h_prev.data()),\n",
    "                    thrust::raw_pointer_cast(d_buffer.data()),\n",
    "                    height * width * sizeof(float), cudaMemcpyDeviceToHost,\n",
    "                    copy_stream);\n",
    "\n",
    "    for (int compute_step = 0; compute_step < compute_steps; compute_step++) \n",
    "    {\n",
    "      dli::simulate(width, height, d_prev, d_next, compute_stream);\n",
    "      d_prev.swap(d_next);\n",
    "    }\n",
    "\n",
    "    cudaStreamSynchronize(copy_stream);\n",
    "    dli::store(write_step, height, width, h_prev);\n",
    "\n",
    "    cudaStreamSynchronize(compute_stream);\n",
    "  }\n",
    "\n",
    "  cudaStreamDestroy(compute_stream);\n",
    "  cudaStreamDestroy(copy_stream);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc --extended-lambda -o /tmp/a.out Sources/copy-overlap.cu # build executable\n",
    "!nsys profile --force-overwrite true -o ../nsight-reports/pinned /tmp/a.out # run and profile executable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you’re unsure how to proceed, consider expanding this section for guidance. Use the hint only after giving the problem a genuine attempt.\n",
    "\n",
    "<details>\n",
    "  <summary>Hints</summary>\n",
    "  \n",
    "  - You can allocate pinned memory with `thrust::universal_host_pinned_vector`\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open this section only after you’ve made a serious attempt at solving the problem. Once you’ve completed your solution, compare it with the reference provided here to evaluate your approach and identify any potential improvements.\n",
    "\n",
    "<details>\n",
    "  <summary>Solution</summary>\n",
    "\n",
    "  Key points:\n",
    "\n",
    "  - Use `thrust::universal_host_pinned_vector` to allocate pinned memory for the host buffer\n",
    "\n",
    "  Solution:\n",
    "  ```c++\n",
    "  thrust::universal_host_pinned_vector<float> h_prev(height * width);\n",
    "\n",
    "  const int compute_steps = 750;\n",
    "  const int write_steps = 3;\n",
    "  for (int write_step = 0; write_step < write_steps; write_step++) {\n",
    "    cudaMemcpy(thrust::raw_pointer_cast(d_buffer.data()),\n",
    "               thrust::raw_pointer_cast(d_prev.data()),\n",
    "               height * width * sizeof(float), cudaMemcpyDeviceToDevice);\n",
    "    cudaMemcpyAsync(thrust::raw_pointer_cast(h_prev.data()),\n",
    "                    thrust::raw_pointer_cast(d_buffer.data()),\n",
    "                    height * width * sizeof(float), cudaMemcpyDeviceToHost,\n",
    "                    copy_stream);\n",
    "    // ...\n",
    "  }\n",
    "  ```\n",
    "\n",
    "  You can find the full solution [here](Solutions/copy-overlap.cu).\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Congratulations!  You've completed the Asynchrony and Streams lab.\n",
    "Proceed to [the summary](../02.05-Summary/02.05.01-Summary.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/nvidia_header.png\" style=\"margin-left: -30px; width: 300px; float: left;\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
